# 👋 Hi, I’m Divyansh Singhvi  

<p align="center">
  <img src="https://github-readme-stats.vercel.app/api?username=divyanshsinghvi&show_icons=true&hide=issues,contribs&theme=dracula" alt="Divyansh's GitHub stats" />
  <img src="https://github-readme-stats.vercel.app/api/top-langs/?username=divyanshsinghvi&layout=compact&theme=dracula" alt="Top Langs" />
</p>

---

## 🚀 About Me
<!-- - 📖 Co-author of an ACL 2025 paper on interpretability in LLMs  -->  
<!-- - 🧑‍💻 Open-source contributor (vLLM, PyTorch, mechanistic interpretability repos)  -->
- 🌱 Currently exploring **reinforcement learning** & **mechanistic interpretability**  
- 💡 I enjoy building **scalable ML infra**, doing **applied research**, and **teaching/explaining ideas**  

---

## 🔗 Connect with Me
<p align="center">
  <a href="https://github.com/divyanshsinghvi"><img src="https://img.shields.io/badge/GitHub-black?logo=github&logoColor=white" alt="GitHub"></a>
  <a href="https://www.linkedin.com/in/divyanshsinghvi/"><img src="https://img.shields.io/badge/LinkedIn-blue?logo=linkedin&logoColor=white" alt="LinkedIn"></a>
  <a href="mailto:divyanshsinghvi9@gmail.com"><img src="https://img.shields.io/badge/Email-D14836?logo=gmail&logoColor=white" alt="Email"></a>
</p>

---


